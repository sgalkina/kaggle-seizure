{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/Users/svegal/Downloads/train_{}/\"\n",
    "TRAIN_DATA_CHUNKS = (1, )\n",
    "PREICTAL = 1\n",
    "INTERICTAL = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "Load samples of interictal and preictal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_to_pandas(path):\n",
    "    mat = loadmat(path, verify_compressed_data_integrity=False)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    return pd.DataFrame(ndata['data'], columns=ndata['channelIndices'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "IGNORED_FILES = set(['.DS_Store'])\n",
    "\n",
    "def is_class(class_id, filename):\n",
    "    if filename in IGNORED_FILES:\n",
    "        return False\n",
    "    return int(filename.rstrip('.mat')[-1]) == class_id\n",
    "\n",
    "def filenames_for_class(path, class_id, n_filenames):\n",
    "    return random.sample([f for f in os.listdir(path) if is_class(class_id, f)], n_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interictal 1152\n",
      "Preictal 150\n"
     ]
    }
   ],
   "source": [
    "path = TRAIN_DATA_PATH.format(TRAIN_DATA_CHUNKS[0])\n",
    "print(\"Interictal\", len([f for f in os.listdir(path) if is_class(0, f)]))\n",
    "print(\"Preictal\", len([f for f in os.listdir(path) if is_class(1, f)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_correlations(channels_data):\n",
    "    correlations = None\n",
    "    for i in range(16):\n",
    "        correlations_i = np.array([])\n",
    "        for j in range (16):\n",
    "            if i != j:\n",
    "                corr_i = correlate(channels_data[i], channels_data[j], mode='same')\n",
    "                correlations_i = np.concatenate([correlations_i, corr_i])\n",
    "        correlations = np.vstack([correlations, correlations_i]) if correlations is not None else correlations_i\n",
    "    return np.column_stack([channels_data, correlations])\n",
    "\n",
    "\n",
    "def generate_features(data):\n",
    "    channels_data = resample(data.transpose(), 600, axis=1, window=400)  # 1 entry per second\n",
    "    channels_data = add_correlations(channels_data)\n",
    "    return channels_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "def train_dataset(n_files, n_preictal):\n",
    "    \"\"\"Create a train dataset from randomly chosen n_files, where the share of preictal data is share_preictal\"\"\"\n",
    "    PATH = TRAIN_DATA_PATH.format(TRAIN_DATA_CHUNKS[0])\n",
    "    n_interictal = n_files - n_preictal\n",
    "    X = None\n",
    "    y = None\n",
    "    for i, n in enumerate([n_interictal, n_preictal]):\n",
    "        filenames = filenames_for_class(PATH, i, n)\n",
    "        for f in filenames:\n",
    "            channels_data = generate_features(mat_to_pandas(PATH + '/' + f))\n",
    "            y_data = np.repeat(i, 16, axis=0)\n",
    "            X = np.vstack([X, channels_data]) if X is not None else channels_data\n",
    "            y = np.concatenate([y, y_data]) if y is not None else y_data\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 46.8 s, total: 2min 2s\n",
      "Wall time: 2min 10s\n",
      "(4800, 9600) (4800,)\n"
     ]
    }
   ],
   "source": [
    "%time X_half, y_half = train_dataset(300, 150)\n",
    "print(X_half.shape, y_half.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.71441032e-05,   2.25850828e-05,   2.64450612e-05, ...,\n",
       "          1.29462891e-03,   2.01110609e-03,   1.60979130e-03],\n",
       "       [ -1.72742677e-05,  -1.94196783e-05,  -1.02782028e-05, ...,\n",
       "         -1.56526192e-04,  -3.73398047e-04,  -6.34001805e-04],\n",
       "       [  1.17846002e-06,   1.74172701e-05,   1.20380717e-05, ...,\n",
       "         -2.98124539e-03,  -2.38665110e-03,  -1.48251133e-03],\n",
       "       ..., \n",
       "       [ -2.62965026e-05,   6.79575209e-05,   2.47284413e-05, ...,\n",
       "          2.24133631e-03,   9.69818857e-04,  -2.37030196e-03],\n",
       "       [  1.04465608e-04,   4.76027187e-05,  -3.18499957e-05, ...,\n",
       "          1.33280056e-03,   4.47960997e-03,   1.22885411e-03],\n",
       "       [  9.92667152e-05,   5.96727001e-06,   7.01727021e-05, ...,\n",
       "          6.11471182e-03,   7.84554719e-04,   4.06444971e-03]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Normalizes the data\n",
    "normalize(X_half, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "        self.clf = linear_model.LogisticRegression(C=16, n_jobs=3, verbose=5)\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def metrics(model):\n",
    "    funcs = dict(\n",
    "        accuracy_score=accuracy_score, \n",
    "        precision_score=precision_score, \n",
    "        recall_score=recall_score,\n",
    "        f1_score=f1_score,\n",
    "        roc_auc_score=roc_auc_score,\n",
    "    )\n",
    "    result = {k: v(model.y_test, model.y_pred) for k, v in funcs.items()}\n",
    "    for k, v in result.items():\n",
    "        print(k.title(), v)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    }
   ],
   "source": [
    "model_part = Model(X_half, y_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Score 0.619166666667\n",
      "Recall_Score 0.664429530201\n",
      "Precision_Score 0.606431852986\n",
      "F1_Score 0.634107285829\n",
      "Roc_Auc_Score 0.61946642073\n"
     ]
    }
   ],
   "source": [
    "half_metrics = metrics(model_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
