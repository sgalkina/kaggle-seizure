{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"/Users/svegal/Downloads/train_{}/\"\n",
    "TRAIN_DATA_CHUNKS = (1, 2, 3)\n",
    "PREICTAL = 1\n",
    "INTERICTAL = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "\n",
    "Load samples of interictal and preictal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mat_to_pandas(path):\n",
    "    mat = loadmat(path, verify_compressed_data_integrity=False)\n",
    "    names = mat['dataStruct'].dtype.names\n",
    "    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n",
    "    return ndata['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "IGNORED_FILES = set(['.DS_Store'])\n",
    "\n",
    "def is_class(class_id, filename):\n",
    "    if any(list(map(lambda x: filename.endswith(x), IGNORED_FILES))):\n",
    "        return False\n",
    "    return int(filename.rstrip('.mat')[-1]) == class_id\n",
    "\n",
    "def all_filepaths():\n",
    "    result = []\n",
    "    for i in TRAIN_DATA_CHUNKS:\n",
    "        path = TRAIN_DATA_PATH.format(i)\n",
    "        result.extend([path + f for f in os.listdir(path)])\n",
    "    return result\n",
    "\n",
    "def filenames_for_class(class_id, n_filenames):\n",
    "    return random.sample([f for f in all_filepaths() if is_class(class_id, f)], n_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6043\n",
      "Interictal 5592\n",
      "Preictal 450\n"
     ]
    }
   ],
   "source": [
    "all_files = all_filepaths()\n",
    "print(len(all_files))\n",
    "print(\"Interictal\", len([f for f in all_files if is_class(0, f)]))\n",
    "print(\"Preictal\", len([f for f in all_files if is_class(1, f)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "def measures(d, axis):\n",
    "    return [d.min(axis=axis), d.max(axis=axis), d.std(axis=axis), d.mean(axis=axis)]\n",
    "\n",
    "\n",
    "def generate_features(data):\n",
    "    data = data.transpose()\n",
    "    N = 12000\n",
    "    data = data.reshape(10, 24000, 16)\n",
    "    to_stack = []\n",
    "    time_data = resample(data, N, axis=1)\n",
    "    freq_data = np.absolute(fft(time_data, axis=1))\n",
    "    time_data = np.dstack([time_data, time_data.mean(axis=2)])\n",
    "    freq_data = np.dstack([freq_data, freq_data.mean(axis=2)])\n",
    "    for d in [time_data, freq_data]:\n",
    "        to_stack.extend(measures(d, axis=1))\n",
    "#         maxes, meanes, stds = [], [], []\n",
    "#         for i in range(10):\n",
    "#             cov = np.cov(d[i], rowvar=False)\n",
    "#             maxes.append(cov.max())\n",
    "#             meanes.append(cov.mean())\n",
    "#             stds.append(cov.std())\n",
    "#         to_stack.extend([maxes, meanes, stds])\n",
    "    to_stack.append(freq_data.argmax(axis=1))\n",
    "    return np.hstack(to_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_dataset(n_interictal, n_preictal):\n",
    "    \"\"\"Create a train dataset from randomly chosen n_files, where the share of preictal data is share_preictal\"\"\"\n",
    "    PATH = TRAIN_DATA_PATH.format(TRAIN_DATA_CHUNKS[0])\n",
    "    X = None\n",
    "    y = None\n",
    "    files = None\n",
    "    for i, n in enumerate([n_interictal, n_preictal]):\n",
    "        filenames = filenames_for_class(i, n)\n",
    "        for f in filenames:\n",
    "            X_data = generate_features(mat_to_pandas(f))\n",
    "            files_data = np.repeat(f, X_data.shape[0], axis=0).reshape((10, 1))\n",
    "            y_data = np.repeat(i, X_data.shape[0], axis=0)\n",
    "            X = np.vstack([X, X_data]) if X is not None else X_data\n",
    "            y = np.concatenate([y, y_data]) if y is not None else y_data\n",
    "            files = np.concatenate([files, files_data]) if files is not None else files_data\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 31s, sys: 1min 43s, total: 8min 14s\n",
      "Wall time: 8min 38s\n",
      "(13500, 153) (13500,)\n"
     ]
    }
   ],
   "source": [
    "%time X_half, y_half = train_dataset(900, 450)\n",
    "print(X_half.shape, y_half.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.4 s, sys: 10.2 s, total: 48.6 s\n",
      "Wall time: 49.9 s\n",
      "(1350, 153) (1350,)\n"
     ]
    }
   ],
   "source": [
    "%time X, y = train_dataset(90, 45)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Divide 10 minute samples to non-overlapping 1 min samples\n",
    "2. For each 1 minute sample calculate the probability\n",
    "3. Use the mean over 10 samples to calculate the overall 10-minutes interval probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, X, y):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "        self.clf = linear_model.LogisticRegression(penalty='l1', C=16, n_jobs=3, verbose=5)\n",
    "        self.clf.fit(self.X_train, self.y_train)\n",
    "        self.y_pred = self.clf.predict(self.X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "def metrics(model):\n",
    "    funcs = dict(\n",
    "        accuracy_score=accuracy_score, \n",
    "        precision_score=precision_score, \n",
    "        recall_score=recall_score,\n",
    "        f1_score=f1_score,\n",
    "        roc_auc_score=roc_auc_score,\n",
    "    )\n",
    "    result = {k: v(model.y_test, model.y_pred) for k, v in funcs.items()}\n",
    "    for k, v in result.items():\n",
    "        print(k.title(), v)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model_part = Model(X_half, y_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score 0.195017793594\n",
      "Precision_Score 0.472413793103\n",
      "Roc_Auc_Score 0.527585420056\n",
      "Recall_Score 0.122869955157\n",
      "Accuracy_Score 0.664888888889\n"
     ]
    }
   ],
   "source": [
    "half_metrics = metrics(model_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]F1_Score 0.19587628866\n",
      "Precision_Score 0.246753246753\n",
      "Roc_Auc_Score 0.44997486174\n",
      "Recall_Score 0.162393162393\n",
      "Accuracy_Score 0.538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/svm/base.py:920: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(X, y)\n",
    "metrics = metrics(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
